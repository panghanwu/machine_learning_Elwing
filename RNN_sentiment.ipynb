{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_sentiment.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmrVstRKTLdR7o+YlhDjht",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/panghanwu/machine_learning_Elwing/blob/main/RNN_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3cHU_jWN8Nl"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\n",
        "    fname=\"aclImdb.tar.gz\", \n",
        "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "    extract=True,\n",
        ")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HRL5T5nOQID",
        "outputId": "4d2efc98-fbb3-45be-edbd-8b56828b7f1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "def read(path):\n",
        "  with open(path, 'r', encoding='utf-8') as f:\n",
        "    content = f.read()\n",
        "  return content\n",
        "\n",
        "# get path\n",
        "dn = os.path.dirname(dataset)\n",
        "pattern = os.path.join(dn, 'aclImdb', 'train', 'pos', '*')\n",
        "pos = glob.glob(pattern)\n",
        "pattern = os.path.join(dn, 'aclImdb', 'train', 'neg', '*')\n",
        "neg = glob.glob(pattern)\n",
        "sentiments = [1]*len(pos) + [0]*len(neg)\n",
        "\n",
        "contents = map(read, pos+neg)\n",
        "\n",
        "\n",
        "def get_data(t):\n",
        "  dn = os.path.dirname(dataset)\n",
        "  pattern = os.path.join(dn, \"aclImdb\", t, \"pos\", \"*.txt\")\n",
        "  pos = glob.glob(pattern)\n",
        "  pattern = os.path.join(dn, \"aclImdb\", t, \"neg\", \"*.txt\")\n",
        "  neg = glob.glob(pattern)\n",
        "  sentiments = [1] * len(pos) + [0] * len(neg)\n",
        "  contents = map(read, pos + neg)\n",
        "  df = pd.DataFrame({\n",
        "      \"contents\":contents,\n",
        "      \"sentiment\":sentiments\n",
        "  })\n",
        "  return df\n",
        "\n",
        "train_df = get_data('train')\n",
        "test_df = get_data('test')\n",
        "\n",
        "# parameter\n",
        "TOK = 3000\n",
        "LEN = 512\n",
        "EM = 128\n",
        "\n",
        "tok = Tokenizer(num_words=TOK)\n",
        "tok.fit_on_texts(train_df['contents'])\n",
        "\n",
        "x_train_seq = tok.texts_to_sequences(train_df['contents'])\n",
        "x_test_seq = tok.texts_to_sequences(test_df['contents'])\n",
        "\n",
        "x_train_pad = pad_sequences(x_train_seq, LEN)\n",
        "x_test_pad = pad_sequences(x_test_seq, LEN)\n",
        "\n",
        "# build RNN \n",
        "layers = [\n",
        "      Embedding(TOK+1, EM, mask_zero=True, input_length=LEN),\n",
        "      SimpleRNN(64),\n",
        "      Dense(2, activation=\"softmax\")  \n",
        "]\n",
        "\n",
        "model = Sequential(layers)\n",
        "model.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 512, 128)          384128    \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       (None, 64)                12352     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 396,610\n",
            "Trainable params: 396,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6zpRtMKOwpp",
        "outputId": "54e7789b-eeab-43ed-d477-638af3bdda28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "model.compile(loss=SparseCategoricalCrossentropy(),\n",
        "       optimizer=Adam(),\n",
        "       metrics=[\"accuracy\"])\n",
        "\n",
        "y_train = train_df[\"sentiment\"]\n",
        "y_test = test_df[\"sentiment\"]\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\"model.h5\", save_best_only=True),\n",
        "    EarlyStopping(patience=5, restore_best_weights=True)\n",
        "]\n",
        "model.fit(x_train_pad, \n",
        "     y_train,\n",
        "     batch_size=100,\n",
        "     epochs=50,\n",
        "     validation_split=0.1,\n",
        "     callbacks=callbacks)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "225/225 [==============================] - 67s 298ms/step - loss: 0.5995 - accuracy: 0.6756 - val_loss: 0.7898 - val_accuracy: 0.4480\n",
            "Epoch 2/50\n",
            "225/225 [==============================] - 67s 298ms/step - loss: 0.3933 - accuracy: 0.8238 - val_loss: 0.4421 - val_accuracy: 0.8044\n",
            "Epoch 3/50\n",
            "225/225 [==============================] - 70s 311ms/step - loss: 0.2415 - accuracy: 0.9046 - val_loss: 0.5704 - val_accuracy: 0.7652\n",
            "Epoch 4/50\n",
            "225/225 [==============================] - 68s 300ms/step - loss: 0.1289 - accuracy: 0.9533 - val_loss: 0.5337 - val_accuracy: 0.7900\n",
            "Epoch 5/50\n",
            "225/225 [==============================] - 67s 298ms/step - loss: 0.0865 - accuracy: 0.9700 - val_loss: 0.7992 - val_accuracy: 0.7132\n",
            "Epoch 6/50\n",
            "225/225 [==============================] - 67s 298ms/step - loss: 0.0703 - accuracy: 0.9762 - val_loss: 0.6148 - val_accuracy: 0.8136\n",
            "Epoch 7/50\n",
            "225/225 [==============================] - 67s 298ms/step - loss: 0.0174 - accuracy: 0.9961 - val_loss: 1.0136 - val_accuracy: 0.7488\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f55281d8da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-Mr96EkV1Nt",
        "outputId": "63137178-5fec-4290-ab6f-eb8546066057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(x_test_pad, y_test)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 37s 47ms/step - loss: 0.3933 - accuracy: 0.8314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.39333149790763855, 0.8313599824905396]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZtxf8XGR48x"
      },
      "source": [
        "不推薦RNN，無法平行運算，效果也沒有特別好。"
      ]
    }
  ]
}